"""
This file is a bonus file, when run it make select a .pt checkpoint file and plot the loss history stored inside.
It has been fully generated by ChatGpt.
"""

import os
import torch
from datetime import datetime
import matplotlib.pyplot as plt
import numpy as np

def plot_loss_from_ckpt(loss_history, step_history, epoch0=None, smooth=50, show_epoch_markers=True):
    if not isinstance(loss_history, list) or not isinstance(step_history, list):
        print("[plot] loss_history/step_history wrong format.")
        return
    if len(loss_history) == 0 or len(step_history) == 0:
        print("[plot] Empty History.")
        return
    if len(loss_history) != len(step_history):
        print(f"[plot] Differents lenght: loss={len(loss_history)} step={len(step_history)}")
        return

    steps = np.array(step_history, dtype=np.int64)
    losses = np.array(loss_history, dtype=np.float32)

    plt.figure(figsize=(10, 5))
    plt.plot(steps, losses, label="batch loss")

    # moving average (comme ton plot_loss_steps)
    if smooth is not None and smooth > 1 and len(losses) >= smooth:
        kernel = np.ones(smooth, dtype=np.float32) / float(smooth)
        smoothed = np.convolve(losses, kernel, mode="valid")
        plt.plot(steps[smooth - 1:], smoothed, label=f"moving avg ({smooth})")

    # Repères d'epoch (estimés)
    if show_epoch_markers and epoch0 is not None and epoch0 >= 0:
        epochs_completed = int(epoch0) + 1  # chez toi epoch est 0-based
        total_steps = len(steps)

        if epochs_completed > 0:
            steps_per_epoch = total_steps // epochs_completed  # estimation
            if steps_per_epoch > 0:
                # on met une ligne à la fin de chaque epoch estimée
                for e in range(1, epochs_completed):
                    idx = e * steps_per_epoch - 1
                    if 0 <= idx < len(steps):
                        plt.axvline(steps[idx], linestyle="--", linewidth=1)
                plt.text(0.99, 0.02,
                         f"epochs={epochs_completed} | steps/epoch≈{steps_per_epoch}",
                         transform=plt.gca().transAxes,
                         ha="right", va="bottom")

    plt.xlabel("global step")
    plt.ylabel("loss")
    plt.title("Loss per mini-batch (checkpoint)")
    plt.grid(True)
    plt.legend()
    plt.tight_layout()
    plt.show()


def choose_and_inspect_pt(default_dir=None, map_location="cpu", verbose=True):
    import tkinter as tk
    from tkinter import filedialog

    root = tk.Tk()
    root.withdraw()
    root.attributes("-topmost", True)

    path = filedialog.askopenfilename(
        initialdir=default_dir or os.getcwd(),
        title="Choisir un checkpoint .pt",
        filetypes=[("PyTorch checkpoint", "*.pt"), ("All files", "*.*")]
    )
    root.destroy()

    if not path:
        raise SystemExit("Aucun fichier sélectionné. Fin.")

    ckpt = torch.load(path, map_location=map_location, weights_only=False)

    stat = os.stat(path)
    file_info = {
        "file_name": os.path.basename(path),
        "file_path": os.path.abspath(path),
        "file_size_mb": round(stat.st_size / (1024**2), 3),
        "modified_time": datetime.fromtimestamp(stat.st_mtime).isoformat(timespec="seconds"),
    }

    if verbose:
        print("\n" + "=" * 80)
        print("CHECKPOINT INSPECTOR")
        print("=" * 80)
        print(f"Nom        : {file_info['file_name']}")
        print(f"Chemin     : {file_info['file_path']}")
        print(f"Taille     : {file_info['file_size_mb']} MB")
        print(f"Modifié le : {file_info['modified_time']}")

    if not isinstance(ckpt, dict):
        print("\nContenu ckpt non-dict:", type(ckpt))
        print("=" * 80 + "\n")
        return path, ckpt, {"file": file_info}

    epoch0 = ckpt.get("epoch", None)
    step = ckpt.get("step", None)
    loss_hist = ckpt.get("loss_history", None)
    step_hist = ckpt.get("step_history", None)

    if verbose:
        print("\n--- Training ---")
        print(f"epoch (0-based)             : {epoch0}")
        print(f"epochs complétées (1-based) : {(int(epoch0)+1) if epoch0 is not None else None}")
        print(f"global_step (ckpt)          : {step}")
        print("\n--- Meta ---")
        print(ckpt.get("meta", None))
        print("\n--- Historiques ---")
        print(f"loss_history_len: {len(loss_hist) if isinstance(loss_hist, list) else None}")
        print(f"step_history_len: {len(step_hist) if isinstance(step_hist, list) else None}")
        print("=" * 80 + "\n")

    # ✅ Plot fidèle à ton stockage
    if isinstance(loss_hist, list) and isinstance(step_hist, list):
        plot_loss_from_ckpt(loss_hist, step_hist, epoch0=epoch0, smooth=50, show_epoch_markers=True)
    else:
        print("[plot] Pas de loss_history/step_history dans ce checkpoint.")

    summary = {"file": file_info}
    return path, ckpt, summary


if __name__ == "__main__":
    choose_and_inspect_pt(default_dir="tran_stage2", map_location="cpu", verbose=True)
