{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "header_cell"
      },
      "source": [
        "# Task 3: Window Soft-Argmax Evaluation\n",
        "\n",
        "This notebook evaluates the **Window Soft-Argmax** prediction method on:\n",
        "- **3 Baseline Models**: DINOv2, DINOv3, SAM\n",
        "- **3 Fine-Tuned Models**: Using .pth checkpoint files\n",
        "\n",
        "## Key Improvements over Baseline (Argmax)\n",
        "1. **Sub-pixel precision**: Instead of discrete argmax, we use soft-argmax for refinement\n",
        "2. **Noise robustness**: Windowed approach reduces sensitivity to local similarity noise\n",
        "3. **Better PCK at strict thresholds**: Most improvements visible at Œ±=0.05 and Œ±=0.10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "setup_section"
      },
      "source": [
        "## 1. Setup & Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "clone_repo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "300eed17-3095-4e00-e655-a664aa4492e5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'semantic-correspondance'...\n",
            "remote: Enumerating objects: 327, done.\u001b[K\n",
            "remote: Counting objects: 100% (112/112), done.\u001b[K\n",
            "remote: Compressing objects: 100% (83/83), done.\u001b[K\n",
            "remote: Total 327 (delta 63), reused 67 (delta 24), pack-reused 215 (from 1)\u001b[K\n",
            "Receiving objects: 100% (327/327), 3.45 MiB | 6.73 MiB/s, done.\n",
            "Resolving deltas: 100% (186/186), done.\n"
          ]
        }
      ],
      "source": [
        "# Clone repository and install dependencies (Colab only)\n",
        "!rm -rf semantic-correspondance\n",
        "!git clone https://github.com/MarcotteS/semantic-correspondance.git\n",
        "\n",
        "import sys\n",
        "sys.path.append('/content/semantic-correspondance/src')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "imports_cell",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4601b258-cbc7-46bf-9cea-f0abadddcfa5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import json\n",
        "from datetime import datetime\n",
        "from collections import defaultdict\n",
        "import pandas as pd\n",
        "\n",
        "# Import from src\n",
        "from dataset import SPairDataset, collate_fn_correspondence\n",
        "from models import DINOv2Extractor, DINOv3Extractor, SAMExtractor\n",
        "from correspondence import CorrespondenceMatcher\n",
        "from correspondence_softargmax import WindowSoftArgmaxMatcher\n",
        "from evaluation import CorrespondenceEvaluator\n",
        "from analyzer import ResultsAnalyzer\n",
        "\n",
        "# Check GPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "download_section"
      },
      "source": [
        "## 2. Download Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "download_dataset",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "602ee6bc-fe04-4dd6-be98-f5c8ddeb7fa7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset downloaded and extracted!\n"
          ]
        }
      ],
      "source": [
        "# Download SPair-71k dataset\n",
        "if not os.path.exists('SPair-71k') and not os.path.exists('data/SPair-71k'):\n",
        "    !wget -q https://cvlab.postech.ac.kr/research/SPair-71k/data/SPair-71k.tar.gz\n",
        "    !tar -xf SPair-71k.tar.gz\n",
        "    print(\"Dataset downloaded and extracted!\")\n",
        "else:\n",
        "    print(\"Dataset already exists.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "config_section"
      },
      "source": [
        "## 3. Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "config_cell"
      },
      "outputs": [],
      "source": [
        "# ========================================\n",
        "# CONFIGURATION - Edit these paths\n",
        "# ========================================\n",
        "\n",
        "# Path to the dataset\n",
        "DATA_PATH = '.'  # Path where SPair-71k was extracted\n",
        "\n",
        "# Fine-tuned model checkpoints (.pth files)\n",
        "# Set these paths to your fine-tuned model files\n",
        "FINETUNED_CHECKPOINTS = {\n",
        "    'dinov2_finetuned': '/content/drive/MyDrive/semantic-correspondance-project/checkpoints/dinov2_finetuned/last.pt',\n",
        "    'dinov3_finetuned': '/content/drive/MyDrive/semantic-correspondance-project/checkpoints/dinov3_finetuned/last.pt',\n",
        "    'sam_finetuned': '/content/drive/MyDrive/semantic-correspondance-project/checkpoints/sam_finetuned/last.pt',\n",
        "}\n",
        "\n",
        "# DINOv3 specific configuration\n",
        "# You need to clone the dinov3 repo and get access to the checkpoint\n",
        "DINOV3_REPO_DIR = '/content/dinov3'  # Path to cloned DINOv3 repo\n",
        "DINOV3_WEIGHTS = \"dinov3_vitb16_pretrain_lvd1689m-73cec8be.pth\"\n",
        "\n",
        "# SAM specific configuration\n",
        "SAM_CHECKPOINT_PATH = 'sam_vit_b_01ec64.pth'\n",
        "\n",
        "# Window Soft-Argmax parameters\n",
        "WINDOW_SIZE = 5\n",
        "TEMPERATURE = 0.05\n",
        "\n",
        "# Evaluation parameters\n",
        "IMAGE_SIZE_DINOV2 = 518  # For DINOv2 (multiple of 14)\n",
        "IMAGE_SIZE_DINOV3 = 512  # For DINOv3 (multiple of 16)\n",
        "IMAGE_SIZE_SAM = 512     # For SAM\n",
        "BATCH_SIZE = 16\n",
        "NUM_WORKERS = 4\n",
        "\n",
        "# Output directory\n",
        "RESULTS_DIR = './results/task3_evaluation'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "helper_functions"
      },
      "source": [
        "## 4. Helper Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "helpers_cell"
      },
      "outputs": [],
      "source": [
        "def evaluate_model_simple(matcher, dataloader, desc=\"Evaluating\"):\n",
        "    \"\"\"\n",
        "    Evaluate correspondence matcher on a dataset.\n",
        "    Returns metrics dictionary.\n",
        "    \"\"\"\n",
        "    evaluator = CorrespondenceEvaluator(thresholds=[0.05, 0.10, 0.15, 0.20])\n",
        "    matcher.extractor.model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(dataloader, desc=desc):\n",
        "            src_img = batch['src_img']\n",
        "            trg_img = batch['trg_img']\n",
        "            src_kps = batch['src_kps']\n",
        "\n",
        "            pred_kps = matcher.find_correspondences(src_img, trg_img, src_kps)\n",
        "\n",
        "            batch_size = src_img.shape[0]\n",
        "            for b in range(batch_size):\n",
        "                pred_kps_b = pred_kps[b]\n",
        "                # Extract keypoint IDs correctly from collated batch\n",
        "                kps_ids_b = batch['kps_ids'][b]\n",
        "                batch_single = {\n",
        "                    'trg_kps': batch['trg_kps'][b],\n",
        "                    'pckthres': batch['pckthres'][b],\n",
        "                    'n_pts': batch['n_pts'][b],\n",
        "                    'kps_ids': kps_ids_b,\n",
        "                    'pair_idx': batch['pair_idx'][b],\n",
        "                    'category': batch['category'][b],\n",
        "                }\n",
        "                evaluator.update(pred_kps_b, batch_single)\n",
        "\n",
        "    metrics = evaluator.get_metrics()\n",
        "    evaluator.print_summary(metrics)\n",
        "    return metrics\n",
        "\n",
        "\n",
        "def load_finetuned_weights(model, checkpoint_path):\n",
        "    \"\"\"\n",
        "    Load fine-tuned weights from a checkpoint file.\n",
        "    Handles the checkpoint format from the training script.\n",
        "    \"\"\"\n",
        "    if not os.path.exists(checkpoint_path):\n",
        "        print(f\"‚ö†Ô∏è Checkpoint not found: {checkpoint_path}\")\n",
        "        return False\n",
        "\n",
        "    checkpoint = torch.load(checkpoint_path, map_location=device)\n",
        "\n",
        "    # Handle different checkpoint formats\n",
        "    if 'model' in checkpoint:\n",
        "        state_dict = checkpoint['model']\n",
        "    elif 'state_dict' in checkpoint:\n",
        "        state_dict = checkpoint['state_dict']\n",
        "    else:\n",
        "        state_dict = checkpoint\n",
        "\n",
        "    model.load_state_dict(state_dict)\n",
        "    print(f\"‚úÖ Loaded fine-tuned weights from: {checkpoint_path}\")\n",
        "\n",
        "    if 'epoch' in checkpoint:\n",
        "        print(f\"   Epoch: {checkpoint['epoch'] + 1}\")\n",
        "    if 'meta' in checkpoint:\n",
        "        print(f\"   Training config: {checkpoint['meta']}\")\n",
        "\n",
        "    return True\n",
        "\n",
        "\n",
        "def save_results(all_results, output_dir):\n",
        "    \"\"\"\n",
        "    Save all evaluation results to JSON and generate comparison plots.\n",
        "    \"\"\"\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    # Save raw metrics\n",
        "    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
        "    metrics_path = os.path.join(output_dir, f'metrics_{timestamp}.json')\n",
        "\n",
        "    # Convert metrics to JSON-serializable format\n",
        "    def to_json(obj):\n",
        "        if isinstance(obj, dict):\n",
        "            return {str(k): to_json(v) for k, v in obj.items()}\n",
        "        elif isinstance(obj, (list, tuple)):\n",
        "            return [to_json(v) for v in obj]\n",
        "        elif isinstance(obj, (np.integer, np.floating)):\n",
        "            return float(obj)\n",
        "        elif isinstance(obj, np.ndarray):\n",
        "            return obj.tolist()\n",
        "        elif isinstance(obj, torch.Tensor):\n",
        "            return obj.cpu().tolist()\n",
        "        return obj\n",
        "\n",
        "    with open(metrics_path, 'w') as f:\n",
        "        json.dump(to_json(all_results), f, indent=2)\n",
        "\n",
        "    print(f\"‚úÖ Results saved to: {metrics_path}\")\n",
        "    return metrics_path"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "visualization_functions"
      },
      "source": [
        "## 5. Visualization Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "viz_cell"
      },
      "outputs": [],
      "source": [
        "def plot_model_comparison(all_results, save_path=None):\n",
        "    \"\"\"\n",
        "    Create comparison bar chart for all models at different thresholds.\n",
        "    \"\"\"\n",
        "    thresholds = [0.05, 0.10, 0.15, 0.20]\n",
        "    model_names = list(all_results.keys())\n",
        "    n_models = len(model_names)\n",
        "    n_thresholds = len(thresholds)\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(14, 8))\n",
        "\n",
        "    x = np.arange(n_thresholds)\n",
        "    width = 0.8 / n_models\n",
        "\n",
        "    colors = plt.cm.tab10(np.linspace(0, 1, n_models))\n",
        "\n",
        "    for i, (model_name, metrics) in enumerate(all_results.items()):\n",
        "        pck_values = [metrics['overall'][t] for t in thresholds]\n",
        "        offset = (i - n_models/2 + 0.5) * width\n",
        "        bars = ax.bar(x + offset, pck_values, width, label=model_name, color=colors[i], alpha=0.8)\n",
        "\n",
        "        # Add value labels\n",
        "        for bar, val in zip(bars, pck_values):\n",
        "            ax.text(bar.get_x() + bar.get_width()/2., bar.get_height() + 0.5,\n",
        "                   f'{val:.1f}', ha='center', va='bottom', fontsize=8, rotation=90)\n",
        "\n",
        "    ax.set_xlabel('PCK Threshold (Œ±)', fontsize=12)\n",
        "    ax.set_ylabel('PCK (%)', fontsize=12)\n",
        "    ax.set_title('Task 3: Window Soft-Argmax - Model Comparison', fontsize=14, fontweight='bold')\n",
        "    ax.set_xticks(x)\n",
        "    ax.set_xticklabels([f'Œ±={t:.2f}' for t in thresholds])\n",
        "    ax.set_ylim([0, 100])\n",
        "    ax.legend(loc='upper left', fontsize=10)\n",
        "    ax.grid(True, axis='y', alpha=0.3)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    if save_path:\n",
        "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def plot_baseline_vs_finetuned(all_results, save_path=None):\n",
        "    \"\"\"\n",
        "    Compare baseline vs fine-tuned models.\n",
        "    \"\"\"\n",
        "    thresholds = [0.05, 0.10, 0.15, 0.20]\n",
        "\n",
        "    # Separate baseline and fine-tuned\n",
        "    baselines = {k: v for k, v in all_results.items() if 'finetuned' not in k.lower()}\n",
        "    finetuned = {k: v for k, v in all_results.items() if 'finetuned' in k.lower()}\n",
        "\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
        "\n",
        "    # Plot baselines\n",
        "    ax1 = axes[0]\n",
        "    for model_name, metrics in baselines.items():\n",
        "        pck_values = [metrics['overall'][t] for t in thresholds]\n",
        "        ax1.plot(thresholds, pck_values, marker='o', linewidth=2, markersize=8, label=model_name)\n",
        "    ax1.set_xlabel('PCK Threshold (Œ±)', fontsize=12)\n",
        "    ax1.set_ylabel('PCK (%)', fontsize=12)\n",
        "    ax1.set_title('Baseline Models (Soft-Argmax)', fontsize=14, fontweight='bold')\n",
        "    ax1.legend(fontsize=10)\n",
        "    ax1.grid(True, alpha=0.3)\n",
        "    ax1.set_ylim([0, 100])\n",
        "\n",
        "    # Plot fine-tuned\n",
        "    ax2 = axes[1]\n",
        "    for model_name, metrics in finetuned.items():\n",
        "        pck_values = [metrics['overall'][t] for t in thresholds]\n",
        "        ax2.plot(thresholds, pck_values, marker='s', linewidth=2, markersize=8, label=model_name)\n",
        "    ax2.set_xlabel('PCK Threshold (Œ±)', fontsize=12)\n",
        "    ax2.set_ylabel('PCK (%)', fontsize=12)\n",
        "    ax2.set_title('Fine-Tuned Models (Soft-Argmax)', fontsize=14, fontweight='bold')\n",
        "    ax2.legend(fontsize=10)\n",
        "    ax2.grid(True, alpha=0.3)\n",
        "    ax2.set_ylim([0, 100])\n",
        "\n",
        "    plt.tight_layout()\n",
        "    if save_path:\n",
        "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def plot_per_category_comparison(all_results, threshold=0.10, save_path=None):\n",
        "    \"\"\"\n",
        "    Compare per-category performance across models.\n",
        "    \"\"\"\n",
        "    # Get all categories from first model\n",
        "    first_model = list(all_results.values())[0]\n",
        "    categories = sorted(first_model['per_category'].keys())\n",
        "\n",
        "    model_names = list(all_results.keys())\n",
        "    n_models = len(model_names)\n",
        "    n_categories = len(categories)\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(18, 8))\n",
        "\n",
        "    x = np.arange(n_categories)\n",
        "    width = 0.8 / n_models\n",
        "\n",
        "    colors = plt.cm.tab10(np.linspace(0, 1, n_models))\n",
        "\n",
        "    for i, (model_name, metrics) in enumerate(all_results.items()):\n",
        "        pck_values = [metrics['per_category'].get(cat, {}).get(threshold, 0) for cat in categories]\n",
        "        offset = (i - n_models/2 + 0.5) * width\n",
        "        ax.bar(x + offset, pck_values, width, label=model_name, color=colors[i], alpha=0.8)\n",
        "\n",
        "    ax.set_xlabel('Category', fontsize=12)\n",
        "    ax.set_ylabel(f'PCK@{threshold:.2f} (%)', fontsize=12)\n",
        "    ax.set_title(f'Per-Category Performance Comparison (PCK@{threshold:.2f})', fontsize=14, fontweight='bold')\n",
        "    ax.set_xticks(x)\n",
        "    ax.set_xticklabels(categories, rotation=45, ha='right')\n",
        "    ax.set_ylim([0, 100])\n",
        "    ax.legend(loc='upper right', fontsize=9)\n",
        "    ax.grid(True, axis='y', alpha=0.3)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    if save_path:\n",
        "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def create_summary_table(all_results):\n",
        "    \"\"\"\n",
        "    Create a summary DataFrame comparing all models.\n",
        "    \"\"\"\n",
        "    thresholds = [0.05, 0.10, 0.15, 0.20]\n",
        "\n",
        "    data = []\n",
        "    for model_name, metrics in all_results.items():\n",
        "        row = {'Model': model_name}\n",
        "        for t in thresholds:\n",
        "            row[f'PCK@{t:.2f}'] = f\"{metrics['overall'][t]:.2f}%\"\n",
        "        data.append(row)\n",
        "\n",
        "    df = pd.DataFrame(data)\n",
        "    return df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "load_data_section"
      },
      "source": [
        "## 6. Load Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "load_data",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa1c43e9-6930-4178-fd87-12d43dc2828b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading SPair-71k test dataset for DINOv2 (518x518)...\n",
            "Loading SPair-71k test annotations...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12234/12234 [00:01<00:00, 6629.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test dataset DINOv2: 12234 pairs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# Load test dataset for DINOv2 models\n",
        "print(\"Loading SPair-71k test dataset for DINOv2 (518x518)...\")\n",
        "test_dataset_dinov2 = SPairDataset(\n",
        "    datapath=DATA_PATH,\n",
        "    split='test',\n",
        "    img_size=IMAGE_SIZE_DINOV2,\n",
        "    category='all'\n",
        ")\n",
        "\n",
        "test_loader_dinov2 = DataLoader(\n",
        "    test_dataset_dinov2,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=False,\n",
        "    num_workers=NUM_WORKERS,\n",
        "    collate_fn=collate_fn_correspondence\n",
        ")\n",
        "\n",
        "print(f\"Test dataset DINOv2: {len(test_dataset_dinov2)} pairs\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "baseline_section"
      },
      "source": [
        "## 7. Evaluate Baseline Models with Window Soft-Argmax"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dinov2_baseline_section"
      },
      "source": [
        "### 7.1 DINOv2 Baseline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "dinov2_baseline",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f8ed5f01-2bfe-4edf-e30b-4a3c5132e4b4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "EVALUATING: DINOv2 Baseline + Window Soft-Argmax\n",
            "======================================================================\n",
            "Downloading: \"https://github.com/facebookresearch/dinov2/zipball/main\" to /root/.cache/torch/hub/main.zip\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/root/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/swiglu_ffn.py:51: UserWarning: xFormers is not available (SwiGLU)\n",
            "  warnings.warn(\"xFormers is not available (SwiGLU)\")\n",
            "/root/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/attention.py:33: UserWarning: xFormers is not available (Attention)\n",
            "  warnings.warn(\"xFormers is not available (Attention)\")\n",
            "/root/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/block.py:40: UserWarning: xFormers is not available (Block)\n",
            "  warnings.warn(\"xFormers is not available (Block)\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading: \"https://dl.fbaipublicfiles.com/dinov2/dinov2_vitb14/dinov2_vitb14_pretrain.pth\" to /root/.cache/torch/hub/checkpoints/dinov2_vitb14_pretrain.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 330M/330M [00:01<00:00, 261MB/s]\n",
            "DINOv2 Baseline: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 765/765 [40:20<00:00,  3.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "EVALUATION SUMMARY\n",
            "======================================================================\n",
            "\n",
            "üìä Overall PCK:\n",
            "----------------------------------------------------------------------\n",
            "  PCK@0.05: 39.33%\n",
            "  PCK@0.10: 55.85%\n",
            "  PCK@0.15: 64.27%\n",
            "  PCK@0.20: 70.54%\n",
            "\n",
            "üìÅ Per-Category PCK:\n",
            "----------------------------------------------------------------------\n",
            "  aeroplane       ‚Üí 0.05: 56.85% | 0.10: 70.54% | 0.15: 77.04% | 0.20: 82.13%\n",
            "  bicycle         ‚Üí 0.05: 45.63% | 0.10: 62.34% | 0.15: 69.22% | 0.20: 75.66%\n",
            "  bird            ‚Üí 0.05: 69.89% | 0.10: 86.89% | 0.15: 91.84% | 0.20: 95.12%\n",
            "  boat            ‚Üí 0.05: 19.37% | 0.10: 34.82% | 0.15: 45.36% | 0.20: 53.28%\n",
            "  bottle          ‚Üí 0.05: 25.82% | 0.10: 43.57% | 0.15: 52.82% | 0.20: 60.07%\n",
            "  bus             ‚Üí 0.05: 37.56% | 0.10: 51.43% | 0.15: 57.37% | 0.20: 62.19%\n",
            "  car             ‚Üí 0.05: 33.80% | 0.10: 48.78% | 0.15: 54.43% | 0.20: 59.08%\n",
            "  cat             ‚Üí 0.05: 61.44% | 0.10: 69.36% | 0.15: 75.56% | 0.20: 81.51%\n",
            "  chair           ‚Üí 0.05: 24.01% | 0.10: 37.46% | 0.15: 45.65% | 0.20: 54.22%\n",
            "  cow             ‚Üí 0.05: 52.65% | 0.10: 69.13% | 0.15: 77.25% | 0.20: 82.64%\n",
            "  dog             ‚Üí 0.05: 48.54% | 0.10: 67.10% | 0.15: 75.32% | 0.20: 80.53%\n",
            "  horse           ‚Üí 0.05: 47.51% | 0.10: 68.79% | 0.15: 77.91% | 0.20: 82.84%\n",
            "  motorbike       ‚Üí 0.05: 40.18% | 0.10: 57.55% | 0.15: 68.84% | 0.20: 74.40%\n",
            "  person          ‚Üí 0.05: 50.49% | 0.10: 68.06% | 0.15: 75.40% | 0.20: 80.26%\n",
            "  pottedplant     ‚Üí 0.05: 13.53% | 0.10: 33.19% | 0.15: 47.67% | 0.20: 56.24%\n",
            "  sheep           ‚Üí 0.05: 42.89% | 0.10: 63.71% | 0.15: 72.00% | 0.20: 77.61%\n",
            "  train           ‚Üí 0.05: 31.21% | 0.10: 52.15% | 0.15: 62.84% | 0.20: 71.74%\n",
            "  tvmonitor       ‚Üí 0.05: 14.25% | 0.10: 28.30% | 0.15: 37.15% | 0.20: 44.26%\n",
            "\n",
            "üéØ Per-Keypoint PCK (at Œ±=0.10):\n",
            "----------------------------------------------------------------------\n",
            "  Top 10 easiest keypoints:\n",
            "    cat             - Keypoint 7  : 100.00%\n",
            "    cat             - Keypoint 8  : 100.00%\n",
            "    bird            - Keypoint 6  : 99.83%\n",
            "    cat             - Keypoint 6  : 99.78%\n",
            "    bird            - Keypoint 5  : 99.24%\n",
            "    bird            - Keypoint 7  : 98.90%\n",
            "    bird            - Keypoint 4  : 98.35%\n",
            "    dog             - Keypoint 8  : 97.71%\n",
            "    dog             - Keypoint 6  : 97.62%\n",
            "    cow             - Keypoint 6  : 96.67%\n",
            "\n",
            "  Top 10 hardest keypoints:\n",
            "    car             - Keypoint 25 : 21.43%\n",
            "    bicycle         - Keypoint 10 : 20.96%\n",
            "    boat            - Keypoint 7  : 20.45%\n",
            "    tvmonitor       - Keypoint 1  : 20.24%\n",
            "    bottle          - Keypoint 7  : 19.85%\n",
            "    tvmonitor       - Keypoint 15 : 19.21%\n",
            "    boat            - Keypoint 1  : 18.42%\n",
            "    tvmonitor       - Keypoint 3  : 18.38%\n",
            "    tvmonitor       - Keypoint 11 : 15.76%\n",
            "    tvmonitor       - Keypoint 7  : 15.00%\n",
            "\n",
            "üñºÔ∏è  Per-Image PCK Statistics (at Œ±=0.10):\n",
            "----------------------------------------------------------------------\n",
            "  Mean:   53.10%\n",
            "  Median: 55.56%\n",
            "  Std:    30.68%\n",
            "  Min:    0.00%\n",
            "  Max:    100.00%\n",
            "\n",
            "======================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Store all results\n",
        "all_results = {}\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"EVALUATING: DINOv2 Baseline + Window Soft-Argmax\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Initialize DINOv2 extractor\n",
        "dinov2_extractor = DINOv2Extractor(model_name=\"dinov2_vitb14\")\n",
        "\n",
        "# Create Window Soft-Argmax matcher\n",
        "dinov2_matcher = WindowSoftArgmaxMatcher(\n",
        "    feature_extractor=dinov2_extractor,\n",
        "    window_size=WINDOW_SIZE,\n",
        "    temperature=TEMPERATURE\n",
        ")\n",
        "\n",
        "# Evaluate using DINOv2 loader\n",
        "metrics_dinov2 = evaluate_model_simple(dinov2_matcher, test_loader_dinov2, desc=\"DINOv2 Baseline\")\n",
        "all_results['DINOv2_SoftArgmax'] = metrics_dinov2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dinov3_baseline_section"
      },
      "source": [
        "### 7.2 DINOv3 Baseline (Optional - requires setup)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "dinov3_setup",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc1ccec2-6bae-4063-a521-a00ebac49331"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'dinov3' already exists and is not an empty directory.\n",
            "DINOv3 repo cloned.\n",
            "DINOv3 repo already exists.\n"
          ]
        }
      ],
      "source": [
        "# Clone DINOv3 repo if needed\n",
        "!git clone https://github.com/facebookresearch/dinov3.git\n",
        "print(\"DINOv3 repo cloned.\")\n",
        "\n",
        "print(\"DINOv3 repo already exists.\")\n",
        "\n",
        "# Install torchmetrics (required by DINOv3)\n",
        "!pip install -q torchmetrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "dinov3_baseline",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb70d1f0-af86-4691-f3ac-31ac1fd83795"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "EVALUATING: DINOv3 Baseline + Window Soft-Argmax\n",
            "======================================================================\n",
            "Loading SPair-71k test annotations...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12234/12234 [00:02<00:00, 5087.08it/s]\n",
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading: \"file:///content/dinov3_vitb16_pretrain_lvd1689m-73cec8be.pth\" to /root/.cache/torch/hub/checkpoints/dinov3_vitb16_pretrain_lvd1689m-73cec8be.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 327M/327M [00:06<00:00, 53.5MB/s]\n",
            "DINOv3 Baseline:   0%|          | 0/765 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "DINOv3 Baseline: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 765/765 [32:00<00:00,  2.51s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "EVALUATION SUMMARY\n",
            "======================================================================\n",
            "\n",
            "üìä Overall PCK:\n",
            "----------------------------------------------------------------------\n",
            "  PCK@0.05: 33.44%\n",
            "  PCK@0.10: 54.05%\n",
            "  PCK@0.15: 63.03%\n",
            "  PCK@0.20: 68.77%\n",
            "\n",
            "üìÅ Per-Category PCK:\n",
            "----------------------------------------------------------------------\n",
            "  aeroplane       ‚Üí 0.05: 36.86% | 0.10: 55.22% | 0.15: 62.21% | 0.20: 67.58%\n",
            "  bicycle         ‚Üí 0.05: 32.15% | 0.10: 50.88% | 0.15: 58.48% | 0.20: 65.08%\n",
            "  bird            ‚Üí 0.05: 52.97% | 0.10: 77.48% | 0.15: 84.27% | 0.20: 88.06%\n",
            "  boat            ‚Üí 0.05: 11.34% | 0.10: 25.52% | 0.15: 34.20% | 0.20: 41.29%\n",
            "  bottle          ‚Üí 0.05: 25.21% | 0.10: 46.20% | 0.15: 54.56% | 0.20: 60.28%\n",
            "  bus             ‚Üí 0.05: 32.58% | 0.10: 48.12% | 0.15: 55.09% | 0.20: 58.87%\n",
            "  car             ‚Üí 0.05: 32.21% | 0.10: 48.94% | 0.15: 54.65% | 0.20: 59.19%\n",
            "  cat             ‚Üí 0.05: 59.62% | 0.10: 71.62% | 0.15: 76.46% | 0.20: 80.67%\n",
            "  chair           ‚Üí 0.05: 19.91% | 0.10: 37.29% | 0.15: 46.25% | 0.20: 52.52%\n",
            "  cow             ‚Üí 0.05: 44.64% | 0.10: 66.54% | 0.15: 75.48% | 0.20: 81.06%\n",
            "  dog             ‚Üí 0.05: 37.15% | 0.10: 56.37% | 0.15: 65.54% | 0.20: 71.70%\n",
            "  horse           ‚Üí 0.05: 31.59% | 0.10: 56.12% | 0.15: 66.65% | 0.20: 72.96%\n",
            "  motorbike       ‚Üí 0.05: 23.40% | 0.10: 43.80% | 0.15: 55.41% | 0.20: 62.02%\n",
            "  person          ‚Üí 0.05: 39.92% | 0.10: 63.04% | 0.15: 70.88% | 0.20: 76.75%\n",
            "  pottedplant     ‚Üí 0.05: 17.43% | 0.10: 44.11% | 0.15: 57.66% | 0.20: 64.46%\n",
            "  sheep           ‚Üí 0.05: 30.89% | 0.10: 52.08% | 0.15: 63.37% | 0.20: 70.11%\n",
            "  train           ‚Üí 0.05: 32.02% | 0.10: 55.82% | 0.15: 67.02% | 0.20: 73.59%\n",
            "  tvmonitor       ‚Üí 0.05: 27.46% | 0.10: 53.24% | 0.15: 64.44% | 0.20: 70.20%\n",
            "\n",
            "üéØ Per-Keypoint PCK (at Œ±=0.10):\n",
            "----------------------------------------------------------------------\n",
            "  Top 10 easiest keypoints:\n",
            "    cat             - Keypoint 6  : 99.57%\n",
            "    bird            - Keypoint 7  : 98.90%\n",
            "    cat             - Keypoint 8  : 98.48%\n",
            "    cat             - Keypoint 7  : 97.50%\n",
            "    bird            - Keypoint 4  : 97.25%\n",
            "    bird            - Keypoint 5  : 96.97%\n",
            "    bird            - Keypoint 0  : 93.45%\n",
            "    person          - Keypoint 1  : 92.86%\n",
            "    cat             - Keypoint 4  : 92.03%\n",
            "    person          - Keypoint 0  : 91.03%\n",
            "\n",
            "  Top 10 hardest keypoints:\n",
            "    aeroplane       - Keypoint 8  : 19.17%\n",
            "    bicycle         - Keypoint 10 : 18.01%\n",
            "    boat            - Keypoint 2  : 17.84%\n",
            "    aeroplane       - Keypoint 9  : 15.93%\n",
            "    boat            - Keypoint 4  : 15.83%\n",
            "    motorbike       - Keypoint 9  : 15.28%\n",
            "    sheep           - Keypoint 20 : 15.00%\n",
            "    horse           - Keypoint 14 : 14.29%\n",
            "    sheep           - Keypoint 19 : 13.33%\n",
            "    person          - Keypoint 19 : 11.90%\n",
            "\n",
            "üñºÔ∏è  Per-Image PCK Statistics (at Œ±=0.10):\n",
            "----------------------------------------------------------------------\n",
            "  Mean:   48.52%\n",
            "  Median: 50.00%\n",
            "  Std:    31.42%\n",
            "  Min:    0.00%\n",
            "  Max:    100.00%\n",
            "\n",
            "======================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Clean up cache first to be safe (as we had corruption issues before)\n",
        "if os.path.exists(DINOV3_WEIGHTS) and os.path.getsize(DINOV3_WEIGHTS) < 1024*1024:\n",
        "     print(\"‚ö†Ô∏è WARNING: DINOv3 checkpoint file looks too small! Check your path.\")\n",
        "\n",
        "RUN_DINOV3 = True  # Set to True after verifying usage\n",
        "\n",
        "if RUN_DINOV3 and os.path.exists(DINOV3_WEIGHTS):\n",
        "    print(\"=\"*70)\n",
        "    print(\"EVALUATING: DINOv3 Baseline + Window Soft-Argmax\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    # Clear Hub Cache for DINOv3 specifically if it exists to force local load\n",
        "    repo_cache = os.path.join(torch.hub.get_dir(), f\"checkpoints/{os.path.basename(DINOV3_WEIGHTS)}\")\n",
        "    if os.path.exists(repo_cache):\n",
        "         try:\n",
        "             os.remove(repo_cache)\n",
        "         except: pass\n",
        "\n",
        "    # DINOv3 use dedicated size (512 or 224 - multiples of 16)\n",
        "    test_dataset_dinov3 = SPairDataset(\n",
        "        datapath=DATA_PATH,\n",
        "        split='test',\n",
        "        img_size=IMAGE_SIZE_DINOV3,  # 512\n",
        "        category='all'\n",
        "    )\n",
        "    test_loader_dinov3 = DataLoader(\n",
        "        test_dataset_dinov3, batch_size=BATCH_SIZE, shuffle=False,\n",
        "        num_workers=NUM_WORKERS, collate_fn=collate_fn_correspondence\n",
        "    )\n",
        "\n",
        "    dinov3_extractor = DINOv3Extractor(\n",
        "        repo_dir=DINOV3_REPO_DIR,\n",
        "        weights=DINOV3_WEIGHTS\n",
        "    )\n",
        "\n",
        "    dinov3_matcher = WindowSoftArgmaxMatcher(\n",
        "        feature_extractor=dinov3_extractor,\n",
        "        window_size=WINDOW_SIZE,\n",
        "        temperature=TEMPERATURE\n",
        "    )\n",
        "\n",
        "    metrics_dinov3 = evaluate_model_simple(dinov3_matcher, test_loader_dinov3, desc=\"DINOv3 Baseline\")\n",
        "    all_results['DINOv3_SoftArgmax'] = metrics_dinov3\n",
        "else:\n",
        "    print(f\"‚ö†Ô∏è Skipping DINOv3 - configure DINOV3_WEIGHTS (Local path) and set RUN_DINOV3=True\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sam_baseline_section"
      },
      "source": [
        "### 7.3 SAM Baseline (Optional - requires checkpoint)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "sam_setup",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2230f854-2f4b-4b54-98c5-916f2c6385db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SAM checkpoint downloaded.\n"
          ]
        }
      ],
      "source": [
        "# Download SAM checkpoint if needed\n",
        "if not os.path.exists(SAM_CHECKPOINT_PATH):\n",
        "    !wget -q https://dl.fbaipublicfiles.com/segment_anything/sam_vit_b_01ec64.pth\n",
        "    print(\"SAM checkpoint downloaded.\")\n",
        "\n",
        "# Install segment-anything\n",
        "!pip install -q segment-anything"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "sam_baseline",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13548b72-e8c3-426d-edbd-132720a7e5eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "EVALUATING: SAM Baseline + Window Soft-Argmax\n",
            "======================================================================\n",
            "Loading SPair-71k test annotations...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12234/12234 [00:05<00:00, 2345.54it/s]\n",
            "SAM Baseline: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1530/1530 [37:50<00:00,  1.48s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "EVALUATION SUMMARY\n",
            "======================================================================\n",
            "\n",
            "üìä Overall PCK:\n",
            "----------------------------------------------------------------------\n",
            "  PCK@0.05: 13.02%\n",
            "  PCK@0.10: 23.23%\n",
            "  PCK@0.15: 30.51%\n",
            "  PCK@0.20: 36.85%\n",
            "\n",
            "üìÅ Per-Category PCK:\n",
            "----------------------------------------------------------------------\n",
            "  aeroplane       ‚Üí 0.05: 16.01% | 0.10: 25.14% | 0.15: 32.08% | 0.20: 39.40%\n",
            "  bicycle         ‚Üí 0.05: 10.68% | 0.10: 19.24% | 0.15: 25.50% | 0.20: 30.83%\n",
            "  bird            ‚Üí 0.05: 17.50% | 0.10: 30.80% | 0.15: 38.11% | 0.20: 44.92%\n",
            "  boat            ‚Üí 0.05: 7.62% | 0.10: 17.66% | 0.15: 24.81% | 0.20: 30.92%\n",
            "  bottle          ‚Üí 0.05: 14.11% | 0.10: 24.45% | 0.15: 31.49% | 0.20: 38.32%\n",
            "  bus             ‚Üí 0.05: 11.86% | 0.10: 17.93% | 0.15: 22.82% | 0.20: 28.05%\n",
            "  car             ‚Üí 0.05: 13.06% | 0.10: 21.19% | 0.15: 26.17% | 0.20: 30.73%\n",
            "  cat             ‚Üí 0.05: 23.10% | 0.10: 36.01% | 0.15: 44.56% | 0.20: 51.08%\n",
            "  chair           ‚Üí 0.05: 8.76% | 0.10: 15.64% | 0.15: 21.11% | 0.20: 26.31%\n",
            "  cow             ‚Üí 0.05: 14.73% | 0.10: 23.25% | 0.15: 30.70% | 0.20: 37.57%\n",
            "  dog             ‚Üí 0.05: 10.87% | 0.10: 19.87% | 0.15: 27.49% | 0.20: 34.42%\n",
            "  horse           ‚Üí 0.05: 9.06% | 0.10: 16.69% | 0.15: 23.28% | 0.20: 28.44%\n",
            "  motorbike       ‚Üí 0.05: 8.35% | 0.10: 17.23% | 0.15: 22.87% | 0.20: 27.90%\n",
            "  person          ‚Üí 0.05: 16.57% | 0.10: 30.84% | 0.15: 39.32% | 0.20: 44.95%\n",
            "  pottedplant     ‚Üí 0.05: 10.27% | 0.10: 21.81% | 0.15: 27.90% | 0.20: 32.40%\n",
            "  sheep           ‚Üí 0.05: 6.58% | 0.10: 14.32% | 0.15: 20.58% | 0.20: 25.95%\n",
            "  train           ‚Üí 0.05: 13.75% | 0.10: 25.54% | 0.15: 34.71% | 0.20: 43.50%\n",
            "  tvmonitor       ‚Üí 0.05: 12.14% | 0.10: 25.65% | 0.15: 35.56% | 0.20: 42.76%\n",
            "\n",
            "üéØ Per-Keypoint PCK (at Œ±=0.10):\n",
            "----------------------------------------------------------------------\n",
            "  Top 10 easiest keypoints:\n",
            "    person          - Keypoint 3  : 63.81%\n",
            "    person          - Keypoint 0  : 60.90%\n",
            "    person          - Keypoint 1  : 58.10%\n",
            "    car             - Keypoint 23 : 57.14%\n",
            "    bird            - Keypoint 8  : 57.05%\n",
            "    bird            - Keypoint 7  : 56.04%\n",
            "    person          - Keypoint 2  : 54.44%\n",
            "    cat             - Keypoint 0  : 53.95%\n",
            "    car             - Keypoint 12 : 52.78%\n",
            "    tvmonitor       - Keypoint 8  : 51.67%\n",
            "\n",
            "  Top 10 hardest keypoints:\n",
            "    motorbike       - Keypoint 5  : 6.59%\n",
            "    person          - Keypoint 15 : 6.59%\n",
            "    cat             - Keypoint 14 : 6.41%\n",
            "    cow             - Keypoint 17 : 5.56%\n",
            "    person          - Keypoint 17 : 5.36%\n",
            "    sheep           - Keypoint 13 : 5.00%\n",
            "    sheep           - Keypoint 19 : 3.33%\n",
            "    bus             - Keypoint 6  : 0.00%\n",
            "    chair           - Keypoint 13 : 0.00%\n",
            "    sheep           - Keypoint 20 : 0.00%\n",
            "\n",
            "üñºÔ∏è  Per-Image PCK Statistics (at Œ±=0.10):\n",
            "----------------------------------------------------------------------\n",
            "  Mean:   20.15%\n",
            "  Median: 16.67%\n",
            "  Std:    21.44%\n",
            "  Min:    0.00%\n",
            "  Max:    100.00%\n",
            "\n",
            "======================================================================\n"
          ]
        }
      ],
      "source": [
        "RUN_SAM = True  # Set to True after downloading SAM checkpoint\n",
        "\n",
        "if RUN_SAM and os.path.exists(SAM_CHECKPOINT_PATH):\n",
        "    print(\"=\"*70)\n",
        "    print(\"EVALUATING: SAM Baseline + Window Soft-Argmax\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    # SAM uses 512x512 images\n",
        "    test_dataset_sam = SPairDataset(\n",
        "        datapath=DATA_PATH,\n",
        "        split='test',\n",
        "        img_size=IMAGE_SIZE_SAM,\n",
        "        category='all'\n",
        "    )\n",
        "    test_loader_sam = DataLoader(\n",
        "        test_dataset_sam, batch_size=BATCH_SIZE // 2, shuffle=False,  # Smaller batch for memory\n",
        "        num_workers=NUM_WORKERS, collate_fn=collate_fn_correspondence\n",
        "    )\n",
        "\n",
        "    sam_extractor = SAMExtractor(\n",
        "        model_type=\"vit_b\",\n",
        "        checkpoint_path=SAM_CHECKPOINT_PATH,\n",
        "        image_size=IMAGE_SIZE_SAM\n",
        "    )\n",
        "\n",
        "    sam_matcher = WindowSoftArgmaxMatcher(\n",
        "        feature_extractor=sam_extractor,\n",
        "        window_size=WINDOW_SIZE,\n",
        "        temperature=TEMPERATURE\n",
        "    )\n",
        "\n",
        "    metrics_sam = evaluate_model_simple(sam_matcher, test_loader_sam, desc=\"SAM Baseline\")\n",
        "    all_results['SAM_SoftArgmax'] = metrics_sam\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è Skipping SAM - configure and set RUN_SAM=True\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "finetuned_section"
      },
      "source": [
        "## 8. Evaluate Fine-Tuned Models with Window Soft-Argmax"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dinov2_finetuned_section"
      },
      "source": [
        "### 8.1 DINOv2 Fine-Tuned"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dinov2_finetuned"
      },
      "outputs": [],
      "source": [
        "checkpoint_path = FINETUNED_CHECKPOINTS.get('dinov2_finetuned', '')\n",
        "\n",
        "if os.path.exists(checkpoint_path):\n",
        "    print(\"=\"*70)\n",
        "    print(\"EVALUATING: DINOv2 Fine-Tuned + Window Soft-Argmax\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    # Initialize fresh extractor\n",
        "    dinov2_ft_extractor = DINOv2Extractor(model_name=\"dinov2_vitb14\")\n",
        "\n",
        "    # Load fine-tuned weights\n",
        "    if load_finetuned_weights(dinov2_ft_extractor.model, checkpoint_path):\n",
        "        dinov2_ft_matcher = WindowSoftArgmaxMatcher(\n",
        "            feature_extractor=dinov2_ft_extractor,\n",
        "            window_size=WINDOW_SIZE,\n",
        "            temperature=TEMPERATURE\n",
        "        )\n",
        "\n",
        "        # Use DINOv2 loader (518x518)\n",
        "        metrics_dinov2_ft = evaluate_model_simple(dinov2_ft_matcher, test_loader_dinov2, desc=\"DINOv2 Fine-Tuned\")\n",
        "        all_results['DINOv2_FineTuned_SoftArgmax'] = metrics_dinov2_ft\n",
        "else:\n",
        "    print(f\"‚ö†Ô∏è Skipping DINOv2 Fine-Tuned - checkpoint not found: {checkpoint_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dinov3_finetuned_section"
      },
      "source": [
        "### 8.2 DINOv3 Fine-Tuned"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dinov3_finetuned"
      },
      "outputs": [],
      "source": [
        "checkpoint_path = FINETUNED_CHECKPOINTS.get('dinov3_finetuned', '')\n",
        "\n",
        "if RUN_DINOV3 and os.path.exists(checkpoint_path):\n",
        "    print(\"=\"*70)\n",
        "    print(\"EVALUATING: DINOv3 Fine-Tuned + Window Soft-Argmax\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    # Initialize fresh extractor\n",
        "    dinov3_ft_extractor = DINOv3Extractor(\n",
        "        repo_dir=DINOV3_REPO_DIR,\n",
        "        weights=DINOV3_WEIGHTS\n",
        "    )\n",
        "\n",
        "    # Load fine-tuned weights\n",
        "    if load_finetuned_weights(dinov3_ft_extractor.model, checkpoint_path):\n",
        "        dinov3_ft_matcher = WindowSoftArgmaxMatcher(\n",
        "            feature_extractor=dinov3_ft_extractor,\n",
        "            window_size=WINDOW_SIZE,\n",
        "            temperature=TEMPERATURE\n",
        "        )\n",
        "\n",
        "        # Use DINOv3 loader (512x512)\n",
        "        metrics_dinov3_ft = evaluate_model_simple(dinov3_ft_matcher, test_loader_dinov3, desc=\"DINOv3 Fine-Tuned\")\n",
        "        all_results['DINOv3_FineTuned_SoftArgmax'] = metrics_dinov3_ft\n",
        "else:\n",
        "    print(f\"‚ö†Ô∏è Skipping DINOv3 Fine-Tuned - checkpoint not found or DINOv3 not configured\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sam_finetuned_section"
      },
      "source": [
        "### 8.3 SAM Fine-Tuned"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sam_finetuned"
      },
      "outputs": [],
      "source": [
        "checkpoint_path = FINETUNED_CHECKPOINTS.get('sam_finetuned', '')\n",
        "\n",
        "if RUN_SAM and os.path.exists(checkpoint_path):\n",
        "    print(\"=\"*70)\n",
        "    print(\"EVALUATING: SAM Fine-Tuned + Window Soft-Argmax\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    # Initialize fresh extractor\n",
        "    sam_ft_extractor = SAMExtractor(\n",
        "        model_type=\"vit_b\",\n",
        "        checkpoint_path=SAM_CHECKPOINT_PATH,\n",
        "        image_size=IMAGE_SIZE_SAM\n",
        "    )\n",
        "\n",
        "    # Load fine-tuned weights\n",
        "    if load_finetuned_weights(sam_ft_extractor.model, checkpoint_path):\n",
        "        sam_ft_matcher = WindowSoftArgmaxMatcher(\n",
        "            feature_extractor=sam_ft_extractor,\n",
        "            window_size=WINDOW_SIZE,\n",
        "            temperature=TEMPERATURE\n",
        "        )\n",
        "\n",
        "        metrics_sam_ft = evaluate_model_simple(sam_ft_matcher, test_loader_sam, desc=\"SAM Fine-Tuned\")\n",
        "        all_results['SAM_FineTuned_SoftArgmax'] = metrics_sam_ft\n",
        "else:\n",
        "    print(f\"‚ö†Ô∏è Skipping SAM Fine-Tuned - checkpoint not found or SAM not configured\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "results_section"
      },
      "source": [
        "## 9. Results Summary & Visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "summary_table"
      },
      "outputs": [],
      "source": [
        "# Create summary table\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"RESULTS SUMMARY\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "summary_df = create_summary_table(all_results)\n",
        "print(summary_df.to_string(index=False))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "save_results"
      },
      "outputs": [],
      "source": [
        "# Save all results\n",
        "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
        "metrics_path = save_results(all_results, RESULTS_DIR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "plot_comparison"
      },
      "outputs": [],
      "source": [
        "# Plot overall comparison\n",
        "if len(all_results) > 0:\n",
        "    plot_model_comparison(\n",
        "        all_results,\n",
        "        save_path=os.path.join(RESULTS_DIR, 'model_comparison.png')\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "plot_baseline_vs_ft"
      },
      "outputs": [],
      "source": [
        "# Plot baseline vs fine-tuned\n",
        "if len(all_results) > 1:\n",
        "    plot_baseline_vs_finetuned(\n",
        "        all_results,\n",
        "        save_path=os.path.join(RESULTS_DIR, 'baseline_vs_finetuned.png')\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "plot_per_category"
      },
      "outputs": [],
      "source": [
        "# Plot per-category comparison at PCK@0.10\n",
        "if len(all_results) > 0:\n",
        "    plot_per_category_comparison(\n",
        "        all_results,\n",
        "        threshold=0.10,\n",
        "        save_path=os.path.join(RESULTS_DIR, 'per_category_comparison.png')\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "individual_reports"
      },
      "source": [
        "## 10. Generate Individual Model Reports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "generate_reports"
      },
      "outputs": [],
      "source": [
        "# Generate detailed reports for each model\n",
        "for model_name, metrics in all_results.items():\n",
        "    print(f\"\\n{'='*70}\")\n",
        "    print(f\"Generating report for: {model_name}\")\n",
        "    print('='*70)\n",
        "\n",
        "    model_dir = os.path.join(RESULTS_DIR, model_name)\n",
        "    analyzer = ResultsAnalyzer(metrics)\n",
        "    analyzer.generate_report(save_dir=model_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "conclusion"
      },
      "source": [
        "## 11. Conclusion\n",
        "\n",
        "This notebook evaluated the Window Soft-Argmax approach for semantic correspondence on:\n",
        "- Baseline models (DINOv2, DINOv3, SAM)\n",
        "- Fine-tuned models (with loaded .pth checkpoints)\n",
        "\n",
        "The Window Soft-Argmax approach provides:\n",
        "1. **Sub-pixel precision** - More accurate keypoint localization\n",
        "2. **Noise robustness** - Windowed softmax reduces impact of noise\n",
        "3. **Better performance at strict thresholds** - Most visible at Œ±=0.05 and Œ±=0.10\n",
        "\n",
        "Results are saved in the `./results/task3_evaluation/` directory."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}